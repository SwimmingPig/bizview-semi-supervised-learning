{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse_TFRecord\n",
    "This file parses bbox and confidence score from the tfrecord files generated by the storefront detector model on the UCF dataset.\n",
    "And take the bbox information to generate streetview datasets for the Mixmatch SSL model.\n",
    "\n",
    "There are several versions of streetview dataset that can be generated through this file:\n",
    "- streetview_v1: This dataset mixes the TC11 and UCF images. For the UCF, only the max confidence bbox over threshold will be cropped and added into dataset. For the TC11, it will be added as positive examples for both train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies, global variables, and general functions\n",
    "To generate all versions of streetview dataset, this part of the code should be run beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import itertools\n",
    "import os  # used for directory operations\n",
    "import io\n",
    "from PIL import Image  # used to read images from directory\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "# Information from input tfrecord files\n",
    "SOURCE_ID = 'image/source_id'\n",
    "BBOX_CONFIDENCE = 'image/object/bbox/confidence'\n",
    "BBOX_XMIN = 'image/object/bbox/xmin'\n",
    "BBOX_YMIN = 'image/object/bbox/ymin'\n",
    "BBOX_XMAX = 'image/object/bbox/xmax'\n",
    "BBOX_YMAX = 'image/object/bbox/ymax'\n",
    "\n",
    "# confidence threshold for determine as neg/pos examples\n",
    "CONF_THRESHOLD = {'neg': 0.1, 'pos': 0.9}\n",
    "OUTPUT_IMAGE_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads tfrecords and parse the labels and data needed for the new dataset.\n",
    "def read_tfrecord(file_path):\n",
    "    raw_image_dataset = tf.data.TFRecordDataset(file_path)\n",
    "\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\n",
    "        SOURCE_ID: tf.io.FixedLenFeature([], tf.string),\n",
    "        BBOX_CONFIDENCE: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_XMIN: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_YMIN: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_XMAX: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_YMAX: tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    def _parse_image_function(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "    return parsed_image_dataset\n",
    "\n",
    "# Parse and cleanup the labels to a more straigtforward format.\n",
    "def parse_labels(image_features):\n",
    "    # the format of image_features['image/source_id'] is 'cns/path/to/image_file_name.jpg'\n",
    "    img_name = str(image_features[SOURCE_ID].numpy()).split('/')[-1][:-1]\n",
    "    confidence = tf.sparse_tensor_to_dense(image_features[BBOX_CONFIDENCE], default_value=0).numpy()\n",
    "    xmin = tf.sparse_tensor_to_dense(image_features[BBOX_XMIN], default_value=0).numpy()\n",
    "    ymin = tf.sparse_tensor_to_dense(image_features[BBOX_YMIN], default_value=0).numpy()\n",
    "    xmax = tf.sparse_tensor_to_dense(image_features[BBOX_XMAX], default_value=0).numpy()\n",
    "    ymax = tf.sparse_tensor_to_dense(image_features[BBOX_YMAX], default_value=0).numpy()\n",
    "    \n",
    "    bbox = np.vstack((xmin, ymin, xmax, ymax)) # Left, Top, Right, Bottom\n",
    "    \n",
    "    return img_name, confidence, bbox\n",
    "\n",
    "# Transform raw image data and label into a tfexample format.\n",
    "def img2example(img, label):\n",
    "    imgByteArr = io.BytesIO()\n",
    "    img.save(imgByteArr, format='JPEG')\n",
    "    imgByteArr = imgByteArr.getvalue()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[imgByteArr])),\n",
    "        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))}))\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## streetview_v1\n",
    "Run this part of code to build streetview_v1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the bboxes from the parsed_image_dataset that are over threshold and write it into TFrecord file.\n",
    "def write_tfrecord_ucf(parsed_image_dataset, folder_path, writer):\n",
    "    for image_features in parsed_image_dataset:\n",
    "        img_name, confidence, bbox = parse_labels(image_features)\n",
    "\n",
    "        if img_name:\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            label = 0\n",
    "            \n",
    "            if confidence.size > 0 and max(confidence) > CONF_THRESHOLD['pos']:\n",
    "                label = 1\n",
    "                pos = np.argmax(confidence)\n",
    "                bbox = bbox[:, pos]\n",
    "            elif confidence.size == 0 or (confidence.size > 0 and max(confidence) < CONF_THRESHOLD['neg']):\n",
    "                label = 0\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path, \"r\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(img_path + \" is not valid\")\n",
    "                continue\n",
    "\n",
    "            # Exclude all non RGB images\n",
    "            if len(img.getbands()) != 3:\n",
    "                continue\n",
    "\n",
    "            if label:\n",
    "                img = img.crop(bbox)\n",
    "                \n",
    "            img = img.resize(OUTPUT_IMAGE_SIZE)\n",
    "            example = img2example(img, label)\n",
    "            writer.write(example.SerializeToString())            \n",
    "\n",
    "# Write all TC11 images as positive cases into the TFrecord file.\n",
    "def write_tfrecord_tc11(folder_path, writer):\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        label = 1\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path, \"r\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(img_path + \" is not valid\")\n",
    "            continue\n",
    "            \n",
    "        # Exclude all non RGB images\n",
    "        if len(img.getbands()) != 3:\n",
    "            continue\n",
    "\n",
    "        img = img.resize(OUTPUT_IMAGE_SIZE)\n",
    "\n",
    "        example = img2example(img, label)\n",
    "        writer.write(example.SerializeToString())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tfrecord file path\n",
    "INPUT_RECORD_PATH = './streetlearn-detections/'\n",
    "INPUT_UCF_IMG_DIR = './UCF_Streetview_Dataset/raw/'\n",
    "INPUT_TC11_IMG_DIR = './TC11/svt1'\n",
    "INPUT_RECORD_CNT = 1000\n",
    "\n",
    "# name format of the output tfrecord files\n",
    "OUTPUT_RECORD_PATH = \"../ML_DATA/\"\n",
    "OUTPUT_TRAIN_RECORD_FILENAME = \"streetview-train.tfrecord\"\n",
    "OUTPUT_TEST_RECORD_FILENAME = \"streetview-test.tfrecord\"\n",
    "\n",
    "# tfrecord file writer\n",
    "train_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TRAIN_RECORD_FILENAME)\n",
    "test_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TEST_RECORD_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test tfrecord for TC11 dataset\n",
    "train_image_path = os.path.join(INPUT_TC11_IMG_DIR, 'train')\n",
    "test_image_path = os.path.join(INPUT_TC11_IMG_DIR, 'test')\n",
    "\n",
    "write_tfrecord_tc11(train_image_path, train_writer)\n",
    "write_tfrecord_tc11(test_image_path, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test tfrecords for UCF dataset\n",
    "for i in range(0.9*INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    write_tfrecord_ucf(parsed_image_dataset, INPUT_UCF_IMG_DIR, train_writer)\n",
    "\n",
    "for i in range(0.9*INPUT_RECORD_CNT, INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    write_tfrecord_ucf(parsed_image_dataset, INPUT_UCF_IMG_DIR, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
