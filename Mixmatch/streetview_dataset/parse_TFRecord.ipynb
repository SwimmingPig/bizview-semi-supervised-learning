{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse_TFRecord\n",
    "This file parses bbox and confidence score from the tfrecord files generated by the storefront detector model on the UCF dataset.\n",
    "And take the bbox information to generate streetview datasets for the Mixmatch SSL model.\n",
    "\n",
    "There are several versions of streetview dataset that can be generated through this file:\n",
    "- streetview_v1: This dataset mixes the TC11 and UCF images. For the UCF, only the max confidence bbox over threshold will be cropped and added into dataset. For the TC11, it will be added as positive examples for both train and test set.\n",
    "- streetview_v2: This is a mixture of TC11 and UCF dataset. Compared to streetview_v1, ALL bbox over threshold will be cropped and added into dataset, instead of only cropping the highest bbox in a image. Also, from this version two views of UCF are removed, there is no marked view and skyview images included in the dataset.\n",
    "- streetview_v3: It's similar to streetview_v2. The difference are:\n",
    "    1. Trainset is unbiased, which means positive and negative examples are equal in quantity.\n",
    "    2. The trainset only contains data from UCF.\n",
    "    3. Testset is a combination of TC11 as positive examples and handpick UCF with confidence <0.2 as negative examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies, global variables, and general functions\n",
    "To generate all versions of streetview dataset, this part of the code should be run beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import itertools\n",
    "import os  # used for directory operations\n",
    "import io\n",
    "from PIL import Image  # used to read images from directory\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "# Information from input tfrecord files\n",
    "SOURCE_ID = 'image/source_id'\n",
    "BBOX_CONFIDENCE = 'image/object/bbox/confidence'\n",
    "BBOX_XMIN = 'image/object/bbox/xmin'\n",
    "BBOX_YMIN = 'image/object/bbox/ymin'\n",
    "BBOX_XMAX = 'image/object/bbox/xmax'\n",
    "BBOX_YMAX = 'image/object/bbox/ymax'\n",
    "\n",
    "# confidence threshold for determine as neg/pos examples\n",
    "CONF_THRESHOLD = {'neg': 0.1, 'pos': 0.9}\n",
    "OUTPUT_IMAGE_SIZE = (64, 64)\n",
    "INPUT_RECORD_CNT = 1000\n",
    "\n",
    "INPUT_RECORD_PATH = './streetlearn-detections/'\n",
    "INPUT_UCF_IMG_DIR = './UCF_Streetview_Dataset/raw/'\n",
    "INPUT_TC11_IMG_DIR = './TC11/svt1'\n",
    "OUTPUT_RECORD_PATH = '../ML_DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads tfrecords and parse the labels and data needed for the new dataset.\n",
    "def read_tfrecord(file_path):\n",
    "    raw_image_dataset = tf.data.TFRecordDataset(file_path)\n",
    "\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\n",
    "        SOURCE_ID: tf.io.FixedLenFeature([], tf.string),\n",
    "        BBOX_CONFIDENCE: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_XMIN: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_YMIN: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_XMAX: tf.io.VarLenFeature(tf.float32),\n",
    "        BBOX_YMAX: tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    def _parse_image_function(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "    return parsed_image_dataset\n",
    "\n",
    "# Parse and cleanup the labels to a more straigtforward format.\n",
    "def parse_labels(image_features):\n",
    "    # the format of image_features['image/source_id'] is 'cns/path/to/image_file_name.jpg'\n",
    "    img_name = str(image_features[SOURCE_ID].numpy()).split('/')[-1][:-1]\n",
    "    confidence = tf.sparse_tensor_to_dense(image_features[BBOX_CONFIDENCE], default_value=0).numpy()\n",
    "    xmin = tf.sparse_tensor_to_dense(image_features[BBOX_XMIN], default_value=0).numpy()\n",
    "    ymin = tf.sparse_tensor_to_dense(image_features[BBOX_YMIN], default_value=0).numpy()\n",
    "    xmax = tf.sparse_tensor_to_dense(image_features[BBOX_XMAX], default_value=0).numpy()\n",
    "    ymax = tf.sparse_tensor_to_dense(image_features[BBOX_YMAX], default_value=0).numpy()\n",
    "    \n",
    "    bbox = np.vstack((xmin, ymin, xmax, ymax)) # Left, Top, Right, Bottom\n",
    "    \n",
    "    return img_name, confidence, bbox\n",
    "\n",
    "# Transform raw image data and label into a tfexample format.\n",
    "def img2example(img, label):\n",
    "    imgByteArr = io.BytesIO()\n",
    "    img.save(imgByteArr, format='JPEG')\n",
    "    imgByteArr = imgByteArr.getvalue()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[imgByteArr])),\n",
    "        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))}))\n",
    "    \n",
    "    return example\n",
    "\n",
    "# Write all images into the test TFrecord file.\n",
    "def write_path2tfrecord(folder_path, label, writer):\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path, \"r\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(img_path + \" is not valid\")\n",
    "            continue\n",
    "            \n",
    "        # Exclude all non RGB images\n",
    "        if len(img.getbands()) != 3:\n",
    "            continue\n",
    "\n",
    "        img = img.resize(OUTPUT_IMAGE_SIZE)\n",
    "\n",
    "        example = img2example(img, label)\n",
    "        writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## streetview_v1\n",
    "Run this part of code to build streetview_v1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the bboxes from the parsed_image_dataset that are over threshold and write it into TFrecord file.\n",
    "def write_tfrecord_ucf_v1(parsed_image_dataset, folder_path, writer):\n",
    "    for image_features in parsed_image_dataset:\n",
    "        img_name, confidence, bbox = parse_labels(image_features)\n",
    "        \n",
    "        if img_name:\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            label = 0\n",
    "            \n",
    "            if confidence.size > 0 and max(confidence) > CONF_THRESHOLD['pos']:\n",
    "                label = 1\n",
    "                pos = np.argmax(confidence)\n",
    "                bbox = bbox[:, pos]\n",
    "            elif confidence.size == 0 or (confidence.size > 0 and max(confidence) < CONF_THRESHOLD['neg']):\n",
    "                label = 0\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path, \"r\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(img_path + \" is not valid\")\n",
    "                continue\n",
    "\n",
    "            # Exclude all non RGB images\n",
    "            if len(img.getbands()) != 3:\n",
    "                continue\n",
    "\n",
    "            if label:\n",
    "                img = img.crop(bbox)\n",
    "                \n",
    "            img = img.resize(OUTPUT_IMAGE_SIZE)\n",
    "            example = img2example(img, label)\n",
    "            writer.write(example.SerializeToString())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name format of the output tfrecord files\n",
    "OUTPUT_TRAIN_RECORD_FILENAME = \"streetview-train.tfrecord\"\n",
    "OUTPUT_TEST_RECORD_FILENAME = \"streetview-test.tfrecord\"\n",
    "\n",
    "# tfrecord file writer\n",
    "train_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TRAIN_RECORD_FILENAME)\n",
    "test_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TEST_RECORD_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test tfrecord for TC11 dataset\n",
    "train_image_path = os.path.join(INPUT_TC11_IMG_DIR, 'train')\n",
    "test_image_path = os.path.join(INPUT_TC11_IMG_DIR, 'test')\n",
    "\n",
    "write_path2tfrecord(train_image_path, 1, train_writer)\n",
    "write_path2tfrecord(test_image_path, 1, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test tfrecords for UCF dataset\n",
    "for i in range(0.9 * INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    write_tfrecord_ucf_v1(parsed_image_dataset, INPUT_UCF_IMG_DIR, train_writer)\n",
    "\n",
    "for i in range(0.9 * INPUT_RECORD_CNT, INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    write_tfrecord_ucf_v1(parsed_image_dataset, INPUT_UCF_IMG_DIR, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## streetview_v2\n",
    "This is a mixture of TC11 and UCF dataset. ALL bbox over threshold will be cropped and added into dataset.\n",
    "Run this part of the code to create the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the bboxes from the parsed_image_dataset that are over threshold and write it into TFrecord file.\n",
    "def write_tfrecord_ucf_v2(parsed_image_dataset, folder_path, writer):\n",
    "    for image_features in parsed_image_dataset:\n",
    "        img_name, confidence, bbox = parse_labels(image_features)\n",
    "        # The format fo the image_name is XXXXXX_Y.jpg, the Y represents the view of the image.\n",
    "        view = img_name.split('.')[0][-1]\n",
    "        \n",
    "        if img_name and view!='5' and view!='0':\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            target = []\n",
    "            if confidence.size > 0:\n",
    "                for i in range(confidence.size):\n",
    "                    if confidence[i] > CONF_THRESHOLD['pos'] or confidence[i] < CONF_THRESHOLD['neg']:\n",
    "                        target.append({'label':int(round(confidence[i])), 'bbox':bbox[:, i]})\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path, \"r\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(img_path + \" is not valid\")\n",
    "                continue\n",
    "        \n",
    "            # Exclude all non RGB images\n",
    "            if len(img.getbands()) != 3:\n",
    "                continue\n",
    "\n",
    "            for t in target:\n",
    "                crop_img = img.crop(t['bbox'])\n",
    "                crop_img = crop_img.resize(OUTPUT_IMAGE_SIZE)\n",
    "\n",
    "                example = img2example(crop_img, t['label'])\n",
    "                writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name format of the output tfrecord files\n",
    "OUTPUT_TRAIN_RECORD_FILENAME = \"streetview_v2_512-train.tfrecord\"\n",
    "OUTPUT_TEST_RECORD_FILENAME = \"streetview_v2_512-test.tfrecord\"\n",
    "\n",
    "# tfrecord file writer\n",
    "train_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TRAIN_RECORD_FILENAME)\n",
    "test_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TEST_RECORD_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test tfrecord for TC11 dataset\n",
    "train_image_path = os.path.join(INPUT_TC11_img_dir, 'train')\n",
    "test_image_path = os.path.join(INPUT_TC11_img_dir, 'test')\n",
    "\n",
    "write_path2tfrecord(train_image_path, 1, train_writer)\n",
    "write_path2tfrecord(test_image_path, 1, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test tfrecords for UCF dataset\n",
    "for i in range(0.9 * INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    write_tfrecord_ucf_v2(parsed_image_dataset, INPUT_UCF_IMG_DIR, train_writer)\n",
    "\n",
    "for i in range(0.9 * INPUT_RECORD_CNT, INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    write_tfrecord_ucf_v2(parsed_image_dataset, INPUT_UCF_IMG_DIR, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## streetview_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "INPUT_UCF_FILTER_IMG_DIR = './UCF_Streetview_Dataset/test/'\n",
    "OUTPUT_UCF_IMG_DIR = './UCF_Streetview_Dataset/crop/'\n",
    "OUTPUT_TEST_RECORD_FILENAME = 'streetview_v3_64-test.tfrecord'\n",
    "OUTPUT_TRAIN_RECORD_FILENAME = 'streetview_v3_64-train.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### streetview_v3-test\n",
    "This test set uses all TC11 images as positive cases, and handpick UCF images with confidence<0.2 as negative cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataset with images lower than the threshold, and store the image names in a list. These images will be handpicked to be used as negative examples in the test set.\n",
    "def filter_image(parsed_image_dataset, folder_path, threshold):\n",
    "    res = []\n",
    "    \n",
    "    for image_features in parsed_image_dataset:\n",
    "        img_name, confidence, bbox = parse_labels(image_features)\n",
    "\n",
    "        if img_name:\n",
    "            target = []\n",
    "            if confidence.size==0 or (confidence.size>0 and max(confidence)<threshold):\n",
    "                res.append(img_name)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter UCF images and copy files for furthur handpicking test set.\n",
    "res = []\n",
    "for i in range(0.9 * INPUT_RECORD_CNT, INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_TFRecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    res.extend(filter_image(parsed_image_dataset, INPUT_UCF_IMG_DIR, 0.2))\n",
    "\n",
    "for file in res:\n",
    "    # The format fo the image_name is XXXXXX_Y.jpg, the Y represents the view of the image.\n",
    "    view = img_name.split('.')[0][-1]\n",
    "    # ignore sky images\n",
    "    if view != '5' and view != '0':\n",
    "        copyfile(INPUT_UCF_IMG_DIR + file, OUTPUT_UCF_IMG_DIR + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build streetview_v3_64-test. Write test tfrecord from TC11 dataset and filtered UCF\n",
    "test_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TEST_RECORD_FILENAME)\n",
    "test_image_path = os.path.join(INPUT_TC11_IMG_DIR, 'img')\n",
    "write_path2tfrecord(test_image_path, 1, test_writer)\n",
    "write_path2tfrecord(INPUT_UCF_FILTER_IMG_DIR, 0, test_writer)\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### streetview_v3-train (Unbiased UCF training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecord_ucf_v3(parsed_image_dataset, folder_path, writer, balance_threshold):\n",
    "    \n",
    "    for image_features in parsed_image_dataset:\n",
    "        img_name, confidence, bbox = parse_labels(image_features)\n",
    "        # The format fo the image_name is XXXXXX_Y.jpg, the Y represents the view of the image.\n",
    "        view = img_name.split('.')[0][-1]\n",
    "        \n",
    "        if img_name and view!='5' and view!='0':\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            target = []\n",
    "            if confidence.size > 0:\n",
    "                for i in range(confidence.size):\n",
    "                    if confidence[i] > CONF_THRESHOLD['pos'] or confidence[i] < CONF_THRESHOLD['neg']:\n",
    "                        target.append({'label':int(round(confidence[i])), 'bbox':bbox[:, i]})\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            try:\n",
    "                img = Image.open(img_path, \"r\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(img_path + \" is not valid\")\n",
    "            \n",
    "            # Exclude all non RGB images\n",
    "            if len(img.getbands()) != 3:\n",
    "                continue\n",
    "\n",
    "            for t in target:\n",
    "                if balance_threshold and cnt[t['label']] > balance_threshold:\n",
    "                    continue\n",
    "                    \n",
    "                cnt[t['label']] += 1\n",
    "                \n",
    "                crop_img = img.crop(t['bbox'])\n",
    "                crop_img = crop_img.resize(OUTPUT_IMAGE_SIZE)\n",
    "\n",
    "                example = img2example(crop_img, t['label'])\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build streetview_v3_64-train\n",
    "train_writer = tf.io.TFRecordWriter(OUTPUT_RECORD_PATH + OUTPUT_TRAIN_RECORD_FILENAME)\n",
    "\n",
    "for i in range(0.9 * INPUT_RECORD_CNT):\n",
    "    file_name = \"./streetlearn_detections_tfexample-\" + str(i).zfill(5) + \"-of-01000.tfrecord\"\n",
    "    parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_PATH, file_name))\n",
    "    UCF_train_cnt += write_tfrecord_ucf_v3(parsed_image_dataset, INPUT_UCF_IMG_DIR, train_writer, threshold=19887)\n",
    "\n",
    "train_writer.close()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
