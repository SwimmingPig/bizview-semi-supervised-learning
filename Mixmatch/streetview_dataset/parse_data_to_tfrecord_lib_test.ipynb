{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse_data_to_tfrecord_library Test\n",
    "\n",
    "This file consists several function test for the functions in the Parse_data_to_tfrecord_lib file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_data_to_tfrecord_lib import img_to_example, read_tfrecord, generate_tfexamples_from_detections, batch_read_write_tfrecords\n",
    "from PIL import Image  # used to read images from directory\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function img_to_example():\n",
    "The function reads in image files and outputs tf.examples. The output should store the information feeded into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = './TC11/svt1/img/19_00.jpg'\n",
    "\n",
    "features={'image': tf.FixedLenFeature([], tf.string),\n",
    "          'label': tf.FixedLenFeature([], tf.int64)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img = Image.open(IMG_PATH, \"r\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(IMG_PATH + \" is not valid\")\n",
    "\n",
    "example = img_to_example(img, label=0)\n",
    "features = tf.io.parse_single_example(example.SerializeToString(), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# The label feature should be value of 0\n",
    "assert features['label'].numpy() == 0\n",
    "\n",
    "# The pixel values of the original image and the stored image should be the same\n",
    "decode_image = tf.image.decode_image(features['image']).numpy()\n",
    "original_image = np.array(img.getdata())\n",
    "assert decode_image.flatten().all() == original_image.flatten().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Test: read_tfrecord()\n",
    "The function should read tfrecord files as input, and return DatasetV1Adapter storing a list of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "# Information from input tfrecord files\n",
    "SOURCE_ID = 'image/source_id'\n",
    "BBOX_CONFIDENCE = 'image/object/bbox/confidence'\n",
    "BBOX_XMIN = 'image/object/bbox/xmin'\n",
    "BBOX_YMIN = 'image/object/bbox/ymin'\n",
    "BBOX_XMAX = 'image/object/bbox/xmax'\n",
    "BBOX_YMAX = 'image/object/bbox/ymax'\n",
    "\n",
    "INPUT_RECORD_DIR = './streetlearn-detections/'\n",
    "file_name = \"./streetlearn_detections_tfexample-00000-of-01000.tfrecord\"\n",
    "\n",
    "ID = \"b'/cns/is-d/home/cityblock-streetsmart/yuxizhang/data/public/streetlearn/003419_2.jpg'\"\n",
    "CONFIDENCE = np.array([0.6700151, 0.45046127, 0.22411232, 0.09745394, 0.07810514, 0.06079888, 0.0587763, 0.05148118])\n",
    "XMIN = np.array([9., 714.,  18., 703., 821., 420., 421., 370.])\n",
    "YMIN = np.array([298., 441., 538., 613., 655., 649., 656., 637.])\n",
    "XMAX = np.array([450., 823., 424., 844., 873., 445., 493., 435.])\n",
    "YMAX = np.array([737., 735., 750., 740., 719., 737., 738., 741.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_DIR, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Check the data in the parsed_image_dataset\n",
    "for example in parsed_image_dataset.take(1):\n",
    "    confidence = example[BBOX_CONFIDENCE].values.numpy()\n",
    "    xmin = example[BBOX_XMIN].values.numpy()\n",
    "    ymin = example[BBOX_YMIN].values.numpy()\n",
    "    xmax = example[BBOX_XMAX].values.numpy()\n",
    "    ymax = example[BBOX_YMAX].values.numpy()\n",
    "    \n",
    "    assert str(example[SOURCE_ID].numpy()) == ID\n",
    "    assert confidence.all() == CONFIDENCE.all()\n",
    "    assert xmin.all() == XMIN.all()\n",
    "    assert ymin.all() == YMIN.all()\n",
    "    assert xmax.all() == XMAX.all()\n",
    "    assert ymax.all() == YMAX.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batch_read_write_tfrecords()\n",
    "This file reads input tfrecords in batches, and process the bboxes that meet the conditions. And write back the labeles, and cropped images to a new tfrecord file.\n",
    "\n",
    "The batch_read_write_tfrecords also utilize read_tfrecord(), generate_tfexamples_from_detections(), write_tfexample_to_tfrecord(), parse_detection_confidences(), strip_top(all)_confidence_bbox(), img_to_example(), read_and_check_image()\n",
    "\n",
    "\n",
    "NOTE: This test is a functional test for all functions listed above. Also, this part is harder to compared to the ground truth. Therefore, a visulization of the results is performed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_RECORD_DIR = './streetlearn-detections/'\n",
    "INPUT_UCF_IMG_DIR = './UCF_Streetview_Dataset/raw/'\n",
    "TF_FILE_DIR = './test_file.tfrecord'\n",
    "writer = tf.io.TFRecordWriter(TF_FILE_DIR)\n",
    "detection_property = {'include_top_camera':True, 'only_keep_top_confidence':True, 'balance':False}\n",
    "file_range = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_read_write_tfrecords(file_range, INPUT_RECORD_DIR, INPUT_UCF_IMG_DIR, writer, detection_property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back the generated tfrecords and check if the data stored inside the file meets the expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files back from the generated tfrecords\n",
    "def parse_tf_records(file_dir):\n",
    "    raw_image_dataset = tf.data.TFRecordDataset(file_dir)\n",
    "\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    def _parse_image_function(example_proto):\n",
    "      # Parse the input tf.Example proto using the dictionary above.\n",
    "      return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "    \n",
    "    return parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_image_dataset = parse_tf_records(TF_FILE_DIR)\n",
    "\n",
    "for image_features in parsed_image_dataset:\n",
    "    print(int(image_features['label']))\n",
    "    image_raw = image_features['image'].numpy()\n",
    "    display.display(display.Image(data=image_raw))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
