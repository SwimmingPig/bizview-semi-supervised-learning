{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse_data_to_tfrecord_library Test\n",
    "\n",
    "This file consists several function test for the functions in the Parse_data_to_tfrecord_lib file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_data_to_tfrecord_lib import img_to_example, read_tfrecord, generate_tfexamples_from_detections, batch_read_write_tfrecords\n",
    "from PIL import Image  # used to read images from directory\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function img_to_example():\n",
    "The function reads in image files and outputs tf.examples. The output should store the information feeded into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = './TC11/svt1/img/19_00.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img = Image.open(IMG_PATH, \"r\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(IMG_PATH + \" is not valid\")\n",
    "\n",
    "example = img_to_example(img, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# The label feature should be a int64_list with value of {value: 0}\n",
    "print(example.features.feature['label'])\n",
    "\n",
    "# The image feature should be a bytes_list storing the image\n",
    "print(example.features.feature['image'].SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Test: read_tfrecord()\n",
    "The function should read tfrecord files as input, and return DatasetV1Adapter storing a list of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "# Information from input tfrecord files\n",
    "SOURCE_ID = 'image/source_id'\n",
    "BBOX_CONFIDENCE = 'image/object/bbox/confidence'\n",
    "BBOX_XMIN = 'image/object/bbox/xmin'\n",
    "BBOX_YMIN = 'image/object/bbox/ymin'\n",
    "BBOX_XMAX = 'image/object/bbox/xmax'\n",
    "BBOX_YMAX = 'image/object/bbox/ymax'\n",
    "\n",
    "INPUT_RECORD_DIR = './streetlearn-detections/'\n",
    "file_name = \"./streetlearn_detections_tfexample-00000-of-01000.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_image_dataset = read_tfrecord(os.path.join(INPUT_RECORD_DIR, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Check the data in the parsed_image_dataset\n",
    "for example in parsed_image_dataset.take(1):\n",
    "    print(type(example[SOURCE_ID]))\n",
    "    print(example[BBOX_CONFIDENCE])\n",
    "    print(example[BBOX_XMIN], example[BBOX_YMIN], example[BBOX_XMAX], example[BBOX_YMAX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batch_read_write_tfrecords()\n",
    "This file reads input tfrecords in batches, and process the bboxes that meet the conditions. And write back the labeles, and cropped images to a new tfrecord file.\n",
    "\n",
    "The batch_read_write_tfrecords also utilize read_tfrecord(), generate_tfexamples_from_detections(), write_tfexample_to_tfrecord(), parse_detection_confidences(), strip_top(all)_confidence_bbox(), img_to_example(), read_and_check_image()\n",
    "\n",
    "Therefore, this test is a functional test for all functions listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_RECORD_DIR = './streetlearn-detections/'\n",
    "INPUT_UCF_IMG_DIR = './UCF_Streetview_Dataset/raw/'\n",
    "TF_FILE_DIR = './test_file.tfrecord'\n",
    "writer = tf.io.TFRecordWriter(TF_FILE_DIR)\n",
    "detection_property = {'include_top_camera':True, 'only_keep_top_confidence':True, 'balance':False}\n",
    "file_range = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_read_write_tfrecords(file_range, INPUT_RECORD_DIR, INPUT_UCF_IMG_DIR, writer, detection_property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back the generated tfrecords and check if the data stored inside the file meets the expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files back from the generated tfrecords\n",
    "def parse_tf_records(file_dir):\n",
    "    raw_image_dataset = tf.data.TFRecordDataset(file_dir)\n",
    "\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    def _parse_image_function(example_proto):\n",
    "      # Parse the input tf.Example proto using the dictionary above.\n",
    "      return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "    \n",
    "    return parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_image_dataset = parse_tf_records(TF_FILE_DIR)\n",
    "\n",
    "for image_features in parsed_image_dataset:\n",
    "    print(int(image_features['label']))\n",
    "    image_raw = image_features['image'].numpy()\n",
    "    display.display(display.Image(data=image_raw))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
